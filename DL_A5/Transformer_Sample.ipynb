{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer, TransformerDecoder, TransformerDecoderLayer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn import Transformer\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch import nn\n",
    "import warnings\n",
    "import random\n",
    "import torch\n",
    "import math\n",
    "import yaml\n",
    "import json\n",
    "import os\n",
    "# warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class index2char():\n",
    "    def __init__(self, root, tokenizer=None):\n",
    "        if tokenizer is None:\n",
    "            with open(root + '/tokenizer.yaml', 'r') as f:\n",
    "                self.tokenizer = yaml.load(f, Loader=yaml.CLoader)\n",
    "        else:\n",
    "            self.tokenizer = tokenizer\n",
    "    \n",
    "    def __call__(self, indices:list, without_token=True):\n",
    "        if type(indices) == Tensor:\n",
    "            indices = indices.tolist()\n",
    "        result = ''.join([self.tokenizer['index_2_char'][i] for i in indices])\n",
    "        if without_token:\n",
    "            result = result.split('[eos]')[0]\n",
    "            result = result.replace('[sos]', '').replace('[eos]', '').replace('[pad]', '')\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(pred:list, target:list) -> float:\n",
    "    \"\"\"\n",
    "    pred: list of strings\n",
    "    target: list of strings\n",
    "\n",
    "    return: accuracy(%)\n",
    "    \"\"\"\n",
    "    if len(pred) != len(target):\n",
    "        raise ValueError('length of pred and target must be the same')\n",
    "    correct = 0\n",
    "    for i in range(len(pred)):\n",
    "        if pred[i] == target[i]:\n",
    "            correct += 1\n",
    "    return correct / len(pred) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_num = 31\n",
    "embedding_dim = 512\n",
    "num_layers = 8\n",
    "num_heads = 8\n",
    "ff_dim = 1024\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpellCorrectionDataset(Dataset):\n",
    "    def __init__(self, root, split:str = 'train', tokenizer=None, padding:int =0):\n",
    "        super(SpellCorrectionDataset, self).__init__()\n",
    "        #load your data here\n",
    "        pass\n",
    "\n",
    "    def tokenize(self, text:str):\n",
    "        # tokenize your text here\n",
    "        # ex: \"data\" -> [4, 1, 20, 1]\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # get your data by index here\n",
    "        # ex: return input_ids, target_ids\n",
    "        # return type: torch.tensor\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000, batch_first: bool = False):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "        self.batch_first = batch_first\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        if self.batch_first:\n",
    "            x = x.transpose(0, 1)\n",
    "            x = x + self.pe[:x.size(0)]\n",
    "            return self.dropout(x.transpose(0, 1))\n",
    "        else:\n",
    "            x = x + self.pe[:x.size(0)]\n",
    "            return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.tok_embedding = nn.Embedding(num_emb, hid_dim)\n",
    "        self.pos_embedding = PositionalEncoding(hid_dim, dropout, max_length, batch_first=True)\n",
    "        # self.layer = <nn.TransformerEncoderLayer>\n",
    "        # self.encoder = <nn.TransformerEncoder>\n",
    "\n",
    "    def forward(self, src, some_mask=\"put all your masks here: mask1, mask2, ...\"):\n",
    "        # tgt = your_embeddings(?)\n",
    "        # src = self.encoder(?)\n",
    "        return src\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.tok_embedding = nn.Embedding(num_emb, hid_dim)\n",
    "        self.pos_embedding = PositionalEncoding(hid_dim, dropout, max_length, batch_first=True)\n",
    "        # self.layer = <nn.TransformerDecoderLayer>\n",
    "        # self.encoder = <nn.TransformerDecoder>\n",
    "\n",
    "    def forward(self, tgt, some_mask=\"put all your masks here: mask1, mask2, ...\"):\n",
    "        # tgt = your_embeddings(?)\n",
    "        # tgt = self.decoder(?)\n",
    "        return tgt\n",
    "\n",
    "class TransformerAutoEncoder(nn.Module):\n",
    "    def __init__(self, num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length=100, encoder=None):\n",
    "        super(TransformerAutoEncoder, self).__init__()\n",
    "        if encoder is None:\n",
    "            self.encoder = Encoder(num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length)\n",
    "        else:\n",
    "            self.encoder = encoder\n",
    "        self.decoder = Decoder(num_emb, hid_dim, n_layers, n_heads, ff_dim, dropout, max_length)\n",
    "\n",
    "    def forward(self, src, tgt, src_pad_mask, tgt_mask, tgt_pad_mask):\n",
    "        # enc_src = self.encoder(?)\n",
    "        # out = self.decoder(?)\n",
    "        return #out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_padding_mask(src, pad_idx):\n",
    "    # detect where the padding value is\n",
    "    return #pad_mask\n",
    "\n",
    "def gen_mask(seq):\n",
    "    # triu mask for decoder\n",
    "    return #mask\n",
    "\n",
    "def get_index(pred, dim=2):\n",
    "    return pred.clone().argmax(dim=dim)\n",
    "\n",
    "def random_change_idx(data: torch.Tensor, prob: float = 0.2):\n",
    "    # randomly change the index of the input data\n",
    "    return #sample\n",
    "\n",
    "def random_masked(data: torch.Tensor, prob: float = 0.2, mask_idx: int = 3):\n",
    "    # randomly mask the input data\n",
    "    return #sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained encoder with random mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can try to pretrain the Encoder here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train our spelling correction transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "i2c = index2char('./data/')\n",
    "\n",
    "trainset = SpellCorrectionDataset('./data/', padding=22)\n",
    "trainloader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "testset = SpellCorrectionDataset('./data/', split='test', padding=22)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False)\n",
    "valset = SpellCorrectionDataset('./data/', split='valid', padding=22)\n",
    "valloader = DataLoader(valset, batch_size=32, shuffle=False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "ce_loss = nn.CrossEntropyLoss(ignore_index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(dataloader, model, device, logout=False):\n",
    "    pred_str_list = []\n",
    "    tgt_str_list = []\n",
    "    input_str_list = []\n",
    "    losses = []\n",
    "    for src, tgt in dataloader:\n",
    "            src, tgt = src.to(device), tgt.to(device)\n",
    "            tgt_input = None#An all pad token tensor with the same shape as tgt and the first token is <sos>\n",
    "            for i in range(tgt.shape[1]-1):\n",
    "                src_pad_mask = None#generate the padding mask\n",
    "                tgt_pad_mask = None#generate the padding mask\n",
    "                tgt_mask = None#generate the mask\n",
    "                pred = model(src, tgt_input, src_pad_mask, tgt_mask, tgt_pad_mask)\n",
    "                # pred = <get the prediction idx from the model>\n",
    "                # assign the prediction idx to the next token of tgt_input\n",
    "            for i in range (tgt.shape[0]):\n",
    "                pred_str_list.append(i2c(tgt_input[i].tolist()))\n",
    "                tgt_str_list.append(i2c(tgt[i].tolist()))\n",
    "                input_str_list.append(i2c(src[i].tolist()))\n",
    "                if logout:\n",
    "                    print('='*30)\n",
    "                    print(f'input: {input_str_list[-1]}')\n",
    "                    print(f'pred: {pred_str_list[-1]}')\n",
    "                    print(f'target: {tgt_str_list[-1]}')\n",
    "            loss = ce_loss(pred[:, :-1, :].permute(0, 2, 1), tgt[:, 1:])\n",
    "            losses.append(loss.item())\n",
    "    print(f\"test_acc: {metrics(pred_str_list, tgt_str_list):.2f}\", f\"test_loss: {sum(losses)/len(losses):.2f}\", end=' | ')\n",
    "    print(f\"[pred: {pred_str_list[0]} target: {tgt_str_list[0]}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder.pretrained_mode = False\n",
    "model = TransformerAutoEncoder(embedding_num, embedding_dim, num_layers, num_heads, ff_dim, dropout).to(device)\n",
    "optimizer = None#choose your optimizer\n",
    "for eps in range(1000):\n",
    "    # train\n",
    "    losses = []\n",
    "    model.train()\n",
    "    i_bar = tqdm(trainloader, unit='iter', desc=f'epoch{eps}')\n",
    "    for src, tgt in i_bar:\n",
    "        src, tgt = src.to(device), tgt.to(device)\n",
    "        # generate the mask and padding mask\n",
    "        src_pad_mask = None#generate the padding mask\n",
    "        tgt_pad_mask = None#generate the padding mask\n",
    "        tgt_mask = None#generate the mask\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(src, tgt, src_pad_mask, tgt_mask, tgt_pad_mask)\n",
    "        loss = ce_loss(\"put your prediction and target here\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.item())\n",
    "        i_bar.set_postfix_str(f\"loss: {sum(losses)/len(losses):.3f}\")\n",
    "    # test\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation(testloader, model, device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        validation(valloader, model, device)\n",
    "    # eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(testloader, model, device, logout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation(valloader, model, device, logout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
